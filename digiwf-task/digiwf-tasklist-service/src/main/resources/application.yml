server:
  port: ${TASKSERVICE_SERVER_PORT}
spring:
  profiles:
    active: no-ldap # this profile is activating mock group resolution and should be replaced by the LDAP-aware client on production
  datasource:
    url: ${TASK_DATASOURCE_URL}
    username: ${TASK_DATASOURCE_USERNAME}
    password: ${TASK_DATASOURCE_PASSWORD}

  jpa:
    generate-ddl: false
    hibernate.ddl-auto: validate
    show-sql: false
    open-in-view: false
    database-platform: ${TASK_JPA_PLATFORM}
  flyway:
    enabled: true
    locations: "classpath:db/migration/{vendor}"
  security:
    oauth2:
      resourceserver:
        jwt:
          issuer-uri: ${SSO_ISSUER_URL}
      client:
        provider:
          keycloak:
            issuer-uri: ${SSO_ISSUER_URL}
            user-name-attribute: lhmObjectID
        registration:
          keycloak:
            provider: keycloak
            client-id: ${SSO_TASK_CLIENT_ID}
            client-secret: ${SSO_TASK_CLIENT_SECRET}
            scope: email, profile, openid  # needed for userInfo endpoint
          keycloak-service-account:
            provider: keycloak
            authorization-grant-type: client_credentials
            client-id: ${SSO_TASK_CLIENT_ID}
            client-secret: ${SSO_TASK_CLIENT_SECRET}
            scope: email, profile, openid  # needed for userInfo endpoint


feign:
  client:
    config:
      jsonschema:
        url: ${ENGINE_REST_ENDPOINT_URL}
      legacy-task:
        url: ${ENGINE_REST_ENDPOINT_URL}
      default:
        url: ${ENGINE_CAMUNDA_REST_ENDPOINT_URL}

ezldap:
  client:
    url: ${EZLDAP_ENDPOINT_URL}

axon:
  serializer:
    events: jackson
    messages: jackson
    general: jackson
  axonserver:
    enabled: false # disable axon server connector
  eventhandling:
    processors:
      "[io.holunda.polyflow.view.jpa.service.task]":
        source: kafkaMessageSourcePolyflowTask
        mode: TRACKING
        threadCount: 1
        batchSize: 1
      "[io.holunda.polyflow.view.jpa.service.data]":
        source: kafkaMessageSourcePolyflowData
        mode: TRACKING
        threadCount: 1
        batchSize: 1

  kafka:
    defaulttopic: not_used_but_must_be_set_to_some_value
    client-id: will_be_set_in_properties_manually
    consumer:
      bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVER}:${KAFKA_BOOTSTRAP_SERVER_PORT}
      event-processor-mode: TRACKING
      auto-offset-reset: earliest
    properties:
      security.protocol: ${KAFKA_SECURITY_PROTOCOL}

polyflow:
  axon:
    kafka:
      enabled: true
      topic-tasks: ${KAFKA_TOPIC_TASKS}
      topic-data-entries: ${KAFKA_TOPIC_DATA_ENTRIES}
  view:
    jpa:
      stored-items: TASK, DATA_ENTRY # currently only tasks and data entries, no process definition or process instances
      payload-attribute-level-limit: 1
      task-filters:
        include: unknown

springdoc:
  swagger-ui:
    oauth:
      clientId: ${SSO_TASK_CLIENT_ID}
      clientSecret: ${SSO_TASK_CLIENT_SECRET}
      realm: ${SSO_REALM}
      appName: DigiWF TaskManagement
    csrf:
      enabled: false
    tryItOutEnabled: true
  writer-with-default-pretty-printer: true

logging:
  level:
    org.apache.kafka.clients.consumer.ConsumerConfig: WARN
    org.apache.kafka.clients.producer.ProducerConfig: WARN
    org.apache.kafka.clients.admin.AdminClientConfig: WARN
    org.camunda.community.rest.client.api: INFO
    org.springframework.security: INFO

digiwf:
  s3service:
    topic: 'dwf-s3-${DIGIWF_ENV}'
    httpAPI: ${DIGIWF_S3_HTTPAPI:http://localhost:8086}

io:
  muenchendigital:
    digiwf:
      s3:
        client:
          documentStorageUrl: '${digiwf.s3service.httpAPI}'
